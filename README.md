===================================================
PySpark Practice Series - Structured Exercises
===================================================

This project contains a series of practical exercises designed to build
hands-on experience with PySpark, Spark SQL, RDDs, and DataFrame workflows.
Each part includes real-world tasks, progressive examples, and step-by-step
cleaning and transformation logic.

------------------------------------------------------------
PART 1: PRACTICING PYSPARK DATAFRAME BASICS
------------------------------------------------------------

- Load and explore structured data with Spark DataFrames.
- Practice using select, filter, groupBy, and withColumn.
- Convert string columns to numeric types and handle null values.
- Understand how PySpark handles lazy execution and optimizes queries.

------------------------------------------------------------
PART 2: WORKING WITH SPARKCONTEXT
------------------------------------------------------------

- Learn how Spark initializes with SparkContext.
- Load and transform data using Spark core functions.
- Practice using actions and transformations on distributed data.

------------------------------------------------------------
PART 3: RDD PRACTICE â€“ FUNCTIONAL DATA TRANSFORMATIONS
------------------------------------------------------------

- Create Resilient Distributed Datasets (RDDs) from raw files.
- Practice functional programming with map, filter, reduceByKey, flatMap.
- Chain multiple transformations to solve structured problems.

------------------------------------------------------------
PART 4: INTEGRATING PYSPARK WITH SQL AND PANDAS
------------------------------------------------------------

- Write SQL queries using Spark SQL engine with spark.sql().
- Practice transforming data across Spark and Pandas.
- Clean, join, filter, and aggregate datasets using both APIs.
- Use hybrid techniques to analyze large datasets efficiently.

------------------------------------------------------------

Each section emphasizes repeatable exercises and workflows that support
practical mastery of PySpark and its ecosystem. This is a practice ground 
for applied learning in big data environments.

